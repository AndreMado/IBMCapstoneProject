{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b66b54f-b193-465c-8028-2d981450d1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /usr/local/spark/python (3.5.0)\n",
      "Collecting py4j==0.10.9.7 (from pyspark)\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m783.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: py4j\n",
      "  Attempting uninstall: py4j\n",
      "    Found existing installation: py4j 0.10.9.5\n",
      "    Uninstalling py4j-0.10.9.5:\n",
      "      Successfully uninstalled py4j-0.10.9.5\n",
      "Successfully installed py4j-0.10.9.7\n",
      "Requirement already satisfied: findspark in /opt/conda/lib/python3.11/site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "441c67ac-e46c-40c3-9148-81049e5502c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9188ad9a-cf5d-4160-b9fd-49043425fb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SparkContext._active_spark_context:\n",
    "    SparkContext._active_spark_context.stop()\n",
    "\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90b80bdb-d3f7-4c1c-8051-673f3dba975d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conectado a Spark en Kubernetes\n"
     ]
    }
   ],
   "source": [
    "SPARK_MASTER_URL = \"spark://spark-master:7077\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(SPARK_MASTER_URL) \\\n",
    "    .appName(\"Jupyter-Spark-K8s\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"✅ Conectado a Spark en Kubernetes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baf810dc-5834-4d5e-9a60-c8e39e62bc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-02-14 00:09:15--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0321EN-SkillsNetwork/Bigdata%20and%20Spark/searchterms.csv\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 198.23.119.245\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|198.23.119.245|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 233457 (228K) [text/csv]\n",
      "Saving to: ‘searchterms.csv.2’\n",
      "\n",
      "searchterms.csv.2   100%[===================>] 227.99K   755KB/s    in 0.3s    \n",
      "\n",
      "2025-02-14 00:09:16 (755 KB/s) - ‘searchterms.csv.2’ saved [233457/233457]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0321EN-SkillsNetwork/Bigdata%20and%20Spark/searchterms.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04b4cc9e-1b40-4dca-a388-71e886a5f7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+--------------+\n",
      "|day|month|year|    searchterm|\n",
      "+---+-----+----+--------------+\n",
      "| 12|   11|2021| mobile 6 inch|\n",
      "| 12|   11|2021| mobile latest|\n",
      "| 12|   11|2021|   tablet wifi|\n",
      "| 12|   11|2021|laptop 14 inch|\n",
      "| 12|   11|2021|     mobile 5g|\n",
      "+---+-----+----+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"searchterms.csv\", header=True, inferSchema=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc76ea53-6e3e-4603-b588-d6d146397576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- searchterm: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"searchterm\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5805543-d79e-4c1b-9679-3228f6bfcdb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21188652-0d43-4515-8e7e-66d861ab0945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90555249-8946-49f3-b466-0f5131ccc1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,desc\n",
    "df.filter(col(\"searchterm\") == \"gaming laptop\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2ee4be2-d18c-410b-98dd-e826dd9e4a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|   searchterm|count|\n",
      "+-------------+-----+\n",
      "|mobile 6 inch| 2312|\n",
      "|    mobile 5g| 2301|\n",
      "|mobile latest| 1327|\n",
      "|       laptop|  935|\n",
      "|  tablet wifi|  896|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"searchterm\").count().orderBy(desc(\"count\")).limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d22bef4f-4f1c-4426-9621-115f8b9ddce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-02-14 00:28:43--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0321EN-SkillsNetwork/Bigdata%20and%20Spark/model.tar.gz\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1490 (1.5K) [application/x-tar]\n",
      "Saving to: ‘model.tar.gz’\n",
      "\n",
      "model.tar.gz        100%[===================>]   1.46K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-02-14 00:28:44 (1.01 GB/s) - ‘model.tar.gz’ saved [1490/1490]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0321EN-SkillsNetwork/Bigdata%20and%20Spark/model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b0e4ff9-5e5f-4f74-8e5c-1af30e178ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c289cefc-d926-4d3e-a988-9cf41fe8aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegressionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "829be0ca-5389-45a3-a0a9-1df8a52e1476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sales_prediction.model/\n",
      "sales_prediction.model/metadata/\n",
      "sales_prediction.model/metadata/part-00000\n",
      "sales_prediction.model/metadata/.part-00000.crc\n",
      "sales_prediction.model/metadata/_SUCCESS\n",
      "sales_prediction.model/metadata/._SUCCESS.crc\n",
      "sales_prediction.model/data/\n",
      "sales_prediction.model/data/part-00000-1db9fe2f-4d93-4b1f-966b-3b09e72d664e-c000.snappy.parquet\n",
      "sales_prediction.model/data/_SUCCESS\n",
      "sales_prediction.model/data/.part-00000-1db9fe2f-4d93-4b1f-966b-3b09e72d664e-c000.snappy.parquet.crc\n",
      "sales_prediction.model/data/._SUCCESS.crc\n"
     ]
    }
   ],
   "source": [
    "!tar -xvzf model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81e5ca45-94f6-45b2-9ac5-47a01d1c7557",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegressionModel.load(\"sales_prediction.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7fc929de-2f6d-4f16-b7d8-045cc4a57d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "def predict(year):\n",
    "    assembler = VectorAssembler(inputCols=[\"year\"], outputCol=\"features\")\n",
    "    data = [[year, 0]]\n",
    "    columns = [\"year\", \"sales\"]\n",
    "    df = spark.createDataFrame(data, columns)\n",
    "    transformed_df = assembler.transform(df).select('features', 'sales')\n",
    "    predictions = model.transform(transformed_df)\n",
    "    predictions.select('prediction').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef48e954-c75f-4067-8f7d-d7ecfc27ff18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|        prediction|\n",
      "+------------------+\n",
      "|175.16564294006457|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308c666e-f51f-4356-8ca2-d89d067dfdcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
