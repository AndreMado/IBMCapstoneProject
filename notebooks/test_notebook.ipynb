{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd35b2bb-36cc-47bc-9e87-2578fff55dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark==3.3.1\n",
      "  Using cached pyspark-3.3.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: py4j==0.10.9.5 in /opt/conda/lib/python3.11/site-packages (from pyspark==3.3.1) (0.10.9.5)\n",
      "Installing collected packages: pyspark\n",
      "  Attempting uninstall: pyspark\n",
      "    Found existing installation: pyspark 3.5.0\n",
      "    Can't uninstall 'pyspark'. No files were found to uninstall.\n",
      "Successfully installed pyspark-3.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark==3.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c05efac-8fce-4541-aca0-21e634972af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in /opt/conda/lib/python3.11/site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e91cc299-cf98-43c2-8c0c-8fedbe1ba1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da432156-f75e-4ff9-a884-25e0076c0ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fd0817c-a98a-452f-aff4-f68a6aa43784",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SparkContext._active_spark_context:\n",
    "    SparkContext._active_spark_context.stop()\n",
    "\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f6d6822-19e5-45f6-8ccc-a47c89735423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conectado a Spark en Kubernetes\n"
     ]
    }
   ],
   "source": [
    "SPARK_MASTER_URL = \"spark://spark-master:7077\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(SPARK_MASTER_URL) \\\n",
    "    .appName(\"Jupyter-Spark-K8s\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"✅ Conectado a Spark en Kubernetes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edc71ffa-ffcd-4bd9-b917-f9920ee50a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bab8a5aa-115e-4c4c-aeb0-2b09f98380cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|height|weight|\n",
      "+------+------+\n",
      "|    46|   2.5|\n",
      "|    51|   3.4|\n",
      "|    54|   4.4|\n",
      "|    57|   5.1|\n",
      "|    60|   5.6|\n",
      "|    61|   6.1|\n",
      "|    63|   6.4|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a simple data set of infant height(cms) weight(kgs) chart.\n",
    "\n",
    "mydata = [[46,2.5],[51,3.4],[54,4.4],[57,5.1],[60,5.6],[61,6.1],[63,6.4]]\n",
    "  \n",
    "# Mention column names of dataframe\n",
    "columns = [\"height\", \"weight\"]\n",
    "  \n",
    "# creating a dataframe\n",
    "mydf = spark.createDataFrame(mydata, columns)\n",
    "  \n",
    "# show data frame\n",
    "mydf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04210a4f-f254-4e88-9236-54f3f571135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"height\"],\n",
    "    outputCol=\"features\")\n",
    "\n",
    "data = assembler.transform(mydf).select('features','weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b434b32a-baf6-4238-9520-a07b7cb9eedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LR model\n",
    "lr = LinearRegression(featuresCol='features', labelCol='weight', maxIter=100)\n",
    "lr.setRegParam(0.1)\n",
    "# Fit the model\n",
    "lrModel = lr.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5355e55b-db93-4c35-a3ab-cf7a263f693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel.save('infantheight2.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eafb83cf-5f75-4a3d-9f10-13aa648b6278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need LinearRegressionModel to load the model\n",
    "from pyspark.ml.regression import LinearRegressionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0ecead5-19bb-4112-9028-ab7651c3c52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegressionModel.load('infantheight2.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0b9caff-8b96-40fa-b0e8-1093cde5ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function converts a scalar number into a dataframe that can be used by the model to predict.\n",
    "def predict(height):\n",
    "    assembler = VectorAssembler(inputCols=[\"height\"], outputCol=\"features\")  # Adjusted input column name\n",
    "    data = [[height, 0]]  # Changed input to reflect height\n",
    "    columns = [\"height\", \"weight\"]  # Updated column names for clarity\n",
    "    df = spark.createDataFrame(data, columns)\n",
    "    transformed_df = assembler.transform(df).select('features', 'weight')  # Updated column selection\n",
    "    predictions = model.transform(transformed_df)\n",
    "    predictions.select('prediction').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2abeb98-d615-4617-8b06-0edabf7f896e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|      prediction|\n",
      "+----------------+\n",
      "|7.86345471977588|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a160fd2-7943-40c5-8fba-0c2529230308",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel.save('babyweightprediction.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "626ee00d-e8ac-4c9e-9f5b-3c568968e9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegressionModel.load('babyweightprediction.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a60cc82-920f-4f0f-ae7f-caf4255e3dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|      prediction|\n",
      "+----------------+\n",
      "|3.46668267111646|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
